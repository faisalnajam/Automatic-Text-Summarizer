{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MFG 598: Final Project\n",
        "\n",
        "Automatic Text Summarization using PageRank Algorithm and Cosine Similarity Matrix\n",
        "\n",
        "Faisal Ali Khan\n",
        "'''"
      ],
      "metadata": {
        "id": "pnqeDKPiNjXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import nltk                                             # Natural Language Toolkit for text processing and analysis\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "\n",
        "import os                                               # Interacting with the operating system\n",
        "import csv                                              # Reading and writing CSV files\n",
        "import pandas as pd                                     # Data manipulation and analysis\n",
        "import numpy as np                                      # Numerical computing\n",
        "import networkx as nx                                   # Graphs and networks (Pager Rank Algoritm)\n",
        "import matplotlib.pyplot as plt                         # Visualization for creating graphs and charts"
      ],
      "metadata": {
        "id": "ROLk6Ny0W2d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the stopwords corpus from NLTK\n",
        "nltk.download('stopwords')\n",
        "# list of commonly used words in English that don't really  contribute to the meaning of text\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "3INAAvm1W6z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes file path as input and return a list of sentences from the file\n",
        "\n",
        "def read_folder(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        filedata = f.read()\n",
        "    file = filedata.split(\". \")\n",
        "\n",
        "    sentences = []                                                              # sentences is a list of lists of words, where each inner list represents a sentence\n",
        "\n",
        "    # Remove non-alphabetic characters from the sentence and split it into a list of words\n",
        "    for sentence in file:                                                              \n",
        "        cleaned_sentence = sentence.replace(\"[^a-zA-Z]\",\" \").split(\" \")         \n",
        "        sentences.append(cleaned_sentence)\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "sj2_HFGJVa1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity between two sentences based on words they share\n",
        "\n",
        "def sentence_similarity(sentence_1, sententence_2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords=[]                                                            # optional list of words to ignore in the sentence comparisons\n",
        "    # Convert all words to lowercase                                            \n",
        "    sentence_1 = [w.lower() for w in sentence_1]                                          # sent1 and sent2 are lists of words representing two sentences\n",
        "    sentence_2 = [w.lower() for w in sentence_2]\n",
        "\n",
        "    # Create a list of all unique words in both sentences\n",
        "    all_words = list(set(sentence_1 + sentence_2))\n",
        "\n",
        "    # Initialize two vectors with zeros, one for each sentence\n",
        "    vector_1 = [0] *len(all_words)\n",
        "    vector_2 = [0] *len(all_words)\n",
        "\n",
        "    # Count the number of occurrences of each word in each sentence\n",
        "    for w in sentence_1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector_1[all_words.index(w)] += 1\n",
        "    for w in sentence_2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector_2[all_words.index(w)] += 1\n",
        "\n",
        "    # Compute the cosine similarity between the two sentence vectors and return the similarity score    \n",
        "    return 1-cosine_distance(vector_1,vector_2)"
      ],
      "metadata": {
        "id": "RBDvKBANXR9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a similarity matrix for a list of sentences\n",
        "\n",
        "def gen_sim_matrix(sentences, stop_words):\n",
        "  \n",
        "    # Initialize a square matrix of zeros with dimensions equal to the number of sentences\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    # Compute similarity score through each pair of sentences\n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "\n",
        "            # Skip comparing a sentence to itself\n",
        "            if idx1 == idx2:\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2]=sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "id": "mxGffA45XVXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate summary for a given file\n",
        "\n",
        "\n",
        "def generate_summary(file_name, top_n=5):                                       # file_name is the path to the file to be summarized\n",
        "                                                                                # top_n is the number of sentences to include in the summary (default is 5)\n",
        "    # Load the list of stop words\n",
        "    stop_words = stopwords.words('english')\n",
        "    \n",
        "    # Read the contents of the file and split it into a list of sentences\n",
        "    sentences = list(map(tuple, read_folder(file_name)))\n",
        "    \n",
        "    # Generate a similarity matrix based on the sentence pairs\n",
        "    sentence_similarity_matrix = gen_sim_matrix(sentences, stop_words)\n",
        "    \n",
        "    # Create a graph from the similarity matrix\n",
        "    sentences_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    \n",
        "    # Compute a PageRank score for each sentence based on the graph\n",
        "    scores = nx.pagerank(sentences_similarity_graph)\n",
        "    \n",
        "    # Rank the sentences by their PageRank scores and select the top N sentences for the summary\n",
        "    ranked_sentence = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "    summarize_text = []\n",
        "    for i in range(top_n):\n",
        "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "    \n",
        "    # Combine the selected sentences into a single string and return the summary\n",
        "    return \". \".join(summarize_text)\n"
      ],
      "metadata": {
        "id": "LdZXtRokbpFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize all text files in a given folder\n",
        "\n",
        "def summarize_files_in_folder(folder_path):                                     # folder_path is the path to the folder containing the text files\n",
        "    summaries = []\n",
        "\n",
        "    # Loop through each file in the folder and generate a summary for each text file\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            summary = generate_summary(file_path)\n",
        "            summaries.append(summary)\n",
        "\n",
        "    # Create a pandas DataFrame to store the summaries, filenames, and grades (which are currently empty)\n",
        "    df = pd.DataFrame(summaries, columns=[\"Summary\"])\n",
        "    df[\"Filename\"] = os.listdir(folder_path)\n",
        "    df[\"Grade\"] = \"\"\n",
        "\n",
        "    # Reorder the columns of the DataFrame\n",
        "    df = df[[\"Filename\", \"Summary\", \"Grade\"]]\n",
        "    \n",
        "    # Return the DataFrame\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "2Bns6wXddu1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaJ2oDj8Wsly"
      },
      "outputs": [],
      "source": [
        "def grade_summaries(df):\n",
        "    for i, row in df.iterrows():\n",
        "        print(\"Filename:\", row[\"Filename\"])\n",
        "        print(row[\"Summary\"])\n",
        "        grade = input(\"Enter grade for this summary: \")\n",
        "        df.loc[i, \"Grade\"] = grade\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grade summaries in a DataFrame\n",
        "\n",
        "def grade_summaries(df):                                                        # df is the DataFrame containing the summaries to grade\n",
        "\n",
        "    # Loop through each row in the DataFrame and prompt the user to enter a grade for each summary\n",
        "    for i, row in df.iterrows():\n",
        "        print(\"Filename:\", row[\"Filename\"])\n",
        "        print(row[\"Summary\"])\n",
        "        grade = input(\"Enter grade for this summary: \")\n",
        "        df.loc[i, \"Grade\"] = grade\n",
        "        \n",
        "    # Return the DataFrame with the grades added\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "p_cwmTTkeaT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the folder containing the text files to summarize\n",
        "folder_path = \"/content/textfiles\"\n",
        "\n",
        "# Summarize the files in the folder and generate a DataFrame of the summaries\n",
        "df = summarize_files_in_folder(folder_path)\n",
        "\n",
        "# Prompt the user to grade the summaries in the DataFrame\n",
        "df = grade_summaries(df)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(\"summaries.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "SAiNvV5fbwYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Visualization\n",
        "\n",
        "# Read the CSV file containing the graded summaries into a pandas DataFrame\n",
        "df = pd.read_csv('summaries.csv')\n",
        "\n",
        "# Create a bar plot of the grades for each summary\n",
        "plt.bar(df['Filename'], df['Grade'])\n",
        "\n",
        "# Rotate the x-axis labels by 90 degrees for better readability\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add x and y axis labels and a plot title\n",
        "plt.xlabel('Filename')\n",
        "plt.ylabel('Grade')\n",
        "plt.title('Summary Grades')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "hgwPkmv1Wu_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}